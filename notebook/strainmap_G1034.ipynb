{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92cf257-f5ac-4a0a-ab60-9c382fdcbf3e",
   "metadata": {},
   "source": [
    "# Sample Map\n",
    "Geolocation of the samples in project: `[{{ project().name }}]`\n",
    "\n",
    "## Description\n",
    "> Map of the strains based on sampling location and visualized using folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c22a7-1270-48f2-a8e4-0f24801a9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.features import DivIcon\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from jinja2 import Template\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def dms_to_dd(degrees, minutes, seconds, direction):\n",
    "    decimal_degrees = degrees + (minutes / 60) + (seconds / 3600)\n",
    "    if direction in ['S', 'W']:\n",
    "        decimal_degrees *= -1\n",
    "    return decimal_degrees\n",
    "\n",
    "def parse_dms(dms_str):\n",
    "    # Extract degrees, minutes, seconds, and direction\n",
    "    parts = re.split('[°\\'\" ]+', dms_str)\n",
    "    degrees = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = float(parts[2])\n",
    "    direction = parts[3]\n",
    "    return dms_to_dd(degrees, minutes, seconds, direction)\n",
    "\n",
    "def convert_coordinates(coordinate_str):\n",
    "    # Function to convert coordinates\n",
    "    parts = re.split('[^\\d\\w]+', coordinate_str)\n",
    "    if len(parts) == 4:\n",
    "        # Assuming format: dd.dddd, dd.dddd\n",
    "        lat = float(parts[0]) + float(parts[1]) / 10000\n",
    "        lon = float(parts[2]) + float(parts[3]) / 10000\n",
    "        return lat, lon\n",
    "    elif len(parts) == 6:\n",
    "        # Assuming format: dd.dddd, ddd.dddd\n",
    "        lat = float(parts[0]) + float(parts[1]) / 10000\n",
    "        lon = float(parts[3]) + float(parts[4]) / 10000\n",
    "        return lat, lon\n",
    "    elif len(parts) == 8 or len(parts) == 10 or len(parts) == 12:\n",
    "        # Assuming format: DMS\n",
    "        lat_str = f\"{parts[0]}°{parts[1]}'{parts[2]}\\\" {parts[3]}\"\n",
    "        lon_str = f\"{parts[4]}°{parts[5]}'{parts[6]}\\\" {parts[7]}\"\n",
    "        lat = parse_dms(lat_str)\n",
    "        lon = parse_dms(lon_str)\n",
    "        return lat, lon\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GPS coordinate format\")\n",
    "\n",
    "\n",
    "def create_popup(row, columns, base_url):\n",
    "    # Function to create popup content from a DataFrame row\n",
    "    popup_content = \"<table style='width:100%; border: 1px solid black; border-collapse: collapse;'>\"\n",
    "    for col in columns:\n",
    "        if col == 'genome_id':\n",
    "            # Create hyperlink for genome_id\n",
    "            popup_content += f\"<tr><th style='border: 1px solid black; padding: 5px;'>{col}</th>\"\n",
    "            popup_content += f\"<td style='border: 1px solid black; padding: 5px;'><a href='{base_url}/{row[col]}' target='_blank'>{row[col]}</a></td></tr>\"\n",
    "        else:\n",
    "            popup_content += f\"<tr><th style='border: 1px solid black; padding: 5px;'>{col}</th>\"\n",
    "            popup_content += f\"<td style='border: 1px solid black; padding: 5px;'>{row[col]}</td></tr>\"\n",
    "    popup_content += \"</table>\"\n",
    "    return popup_content\n",
    "\n",
    "def strainmap(df, outfile, \n",
    "              antismash_server_base=\"localhost:8002/antismash/7.1.0\", \n",
    "              popup_columns=['genome_id', 'latitude', 'longitude'],\n",
    "              tiles=\"cartodb positron\"\n",
    "             ):\n",
    "    \"\"\"\n",
    "    Sample DataFrame:\n",
    "    df = pd.DataFrame({\n",
    "         'genome_id': ['NBC_00076', 'NBC_00077', 'NBC_00078'],\n",
    "         'lat': [55.471, 55.572, 55.673],\n",
    "         'lon': [10.654, 10.754, 10.854],\n",
    "         'location': ['Edinburgh', 'Glasgow', 'Aberdeen'],\n",
    "         'country': ['Scotland', 'Scotland', 'Scotland']\n",
    "    })\n",
    "    \"\"\"\n",
    "    # Calculate the mean latitude and longitude\n",
    "    mean_lat = df['latitude'].mean()\n",
    "    mean_lon = df['longitude'].mean()\n",
    "    \n",
    "    # Initiate map using the calculated mean coordinates as a starting point\n",
    "    m = folium.Map(location=[mean_lat, mean_lon], zoom_start=4, tiles=tiles)\n",
    "    \n",
    "    # Create a marker cluster\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "    \n",
    "    # Fill in data points for the map using marker clusters\n",
    "    for _, row in df.iterrows():\n",
    "        popup_content = create_popup(row, popup_columns, base_url)\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=folium.Popup(popup_content, max_width=300)\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    outfile = Path(outfile)\n",
    "    outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "    m.save(outfile)\n",
    "    \n",
    "    # Display the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885adfa-a9a0-437f-82f5-fe0d5c850664",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir = Path(\"../data/processed/G1032_20240208/\")\n",
    "\n",
    "dependency_version = report_dir / \"metadata/dependency_versions.json\"\n",
    "with open(dependency_version, \"r\") as file:\n",
    "    dependency_version = json.load(file)\n",
    "antismash_version = dependency_version[\"antismash\"]\n",
    "\n",
    "# Load tables with GPS coordinates\n",
    "df_nbc = pd.read_csv(report_dir / f\"tables/df_antismash_{antismash_version}_summary.csv\", low_memory=False)\n",
    "df_taxa = pd.read_csv(report_dir / \"tables/df_gtdb_meta.csv\")\n",
    "df_nbc = df_nbc.merge(df_taxa, left_on=\"genome_id\", right_on=\"genome_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def8e88-9ab6-4d5f-9359-0c442a143d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning GPS data into decimal degrees format\n",
    "converted_data = []\n",
    "for idx in df_nbc.index:\n",
    "    genome_id = df_nbc.loc[idx, \"genome_id\"]\n",
    "    coord = df_nbc.loc[idx, 'gps_coordinates']\n",
    "    if type(coord) == str:\n",
    "        try:\n",
    "            lat, lon = convert_coordinates(coord)\n",
    "            converted_data.append([genome_id, lat, lon])\n",
    "        except (ValueError, TypeError) as ve:\n",
    "            print(f\"Error parsing coordinates {coord}: {ve}\")\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "df_converted = pd.DataFrame(converted_data, columns=['genome_id', 'latitude', 'longitude'])\n",
    "df_converted = df_converted.merge(df_nbc, left_on=\"genome_id\", right_on=\"genome_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cfe8c-dffd-4a8c-ba3c-19a4773216af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many samples don't have GPS\n",
    "df_no_gps = df_nbc[~df_nbc['gps_coordinates'].notna()]\n",
    "df_no_gps.loc[:, ['genome_id', 'gps_coordinates', 'location', 'country', 'soil_sample_name', 'description_of_soil_sample', 'comments', 'bgcs_count', 'bgcs_on_contig_edge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26579b33-279f-47fc-987a-40ae1a0c23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"There are {len(df_no_gps)} genomes that does not have GPS coordinates.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb0a0c-9b8d-408b-b3c2-e9e6248b5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to include in the popup\n",
    "popup_columns = ['genome_id', 'Genus', 'Organism', 'location', 'country', 'soil_sample_name', 'description_of_soil_sample',\n",
    "                'comments', 'bgcs_count', 'bgcs_on_contig_edge']  # Adjust this list based on your DataFrame\n",
    "\n",
    "# Base URL for genome ID links\n",
    "base_url = 'https://nbc.secondarymetabolites.org/nbc/2023-05-22'\n",
    "outfile = Path('../figures/strainmap_G1032_20240208.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737adf5-4c3f-44d1-ac2c-93593baa9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop data without GPS\n",
    "df = df_converted[df_converted['latitude'].notna()]\n",
    "strainmap(df, outfile, antismash_server_base=base_url, popup_columns=popup_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc289fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = Path(\"../tables/df_antismash_7.1.0_summary_with_gps.csv\")\n",
    "outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "df.to_csv(outfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
